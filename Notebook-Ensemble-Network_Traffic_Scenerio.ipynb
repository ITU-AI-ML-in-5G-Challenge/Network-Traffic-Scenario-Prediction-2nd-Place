{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff066b9",
   "metadata": {},
   "source": [
    "# Installing possibly unavailable packages\n",
    "\n",
    "You may comment out those that you have already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061aad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-ligthning\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651c7ae",
   "metadata": {},
   "source": [
    "## Importing the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41818bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import Accuracy\n",
    "from torch import nn, optim\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7f09d",
   "metadata": {},
   "source": [
    "## Let's decide our configuration for this present experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163623e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(\n",
    "    stride=5,  # Stride size used\n",
    "    dropout=0.5,  # dropout to reduce overfitting \n",
    "    num_features=4, # number of features in the dataset (fixed)\n",
    "    num_classes=12, # number of classes in the dataset (fixed)\n",
    "    in_planes=128, # number of first layer proposed channels\n",
    "    scaling='add', # mul|add|const # choosen scaling type for multiple stages\n",
    "    depth=5,  # the number of stages used (default is 4 in all pretrained models)\n",
    "    block_depth=5, # number of layers per stage/block\n",
    "    with_attention=False, # are we using SCSE attention in the decoder?\n",
    "    lr=1e-3,\n",
    "    max_epochs=12, # number of epochs to train for\n",
    "    patience=5, # number of patience epoch for early stopping\n",
    "    scheduler='onecycle',  # onecycle|plateau|cyclic # which scheduler are we using?\n",
    "    seed=42,  # seed to encourage reproducibility\n",
    "    log_dir='logs', # name of folder to save experiments\n",
    "    n_splits=10, # number of splits for cross validation purpose\n",
    "    repeats=1, # >1 means we are repeating the training set during training\n",
    ")\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "args.filename = f\"se-c{args.in_planes}-s{args.depth}-l{args.block_depth}-d{str(args.dropout).split('.')[-1]}-{args.scaling}\"\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385346f9",
   "metadata": {},
   "source": [
    "## The Unet (1D) base model \n",
    "\n",
    "This model was proudly editted from https://www.kaggle.com/code/akashsuper2000/pytorch-u-net-model to encourage experimentation.\n",
    "Edits includes\n",
    "1. Introduction of a variable to control the number of layers per stage(block). Original model uses just 2 layers per block just like the basic UNet architecture.\n",
    "2. Introduction of a variable to control the number of stages(blocks). Original model include just 4 models and this may not be the right choice for the present dataset.\n",
    "3. Introduction of a variable to control the stride. Original model uses a stride size of 2. In this particualr dataset, stride size of 2 was found suboptimal.\n",
    "4. Introduction of dropout with editable probalility to reduce overfitting during training.\n",
    "5. Some other modifications were made in the subfunctions to accommodate the previous mentioned modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec962aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, in_channels//reduction, kernel_size=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(in_channels//reduction, in_channels, kernel_size=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H]\n",
    "        s = F.adaptive_avg_pool1d(x, 1) # [B, C, 1]\n",
    "        s = self.conv1(s) # [B, C//reduction, 1]\n",
    "        s = F.relu(s, inplace=True)\n",
    "        s = self.conv2(s) # [B, C, 1]\n",
    "        x = x + torch.sigmoid(s)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class ConvBR1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, padding=0, dilation=1, stride=1, groups=1, is_activation=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            padding=padding, \n",
    "            dilation=dilation, \n",
    "            stride=stride, \n",
    "            groups=groups, \n",
    "            bias=False)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.is_activation = is_activation\n",
    "        \n",
    "        if is_activation:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.conv(x))\n",
    "        if self.is_activation:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class SENextBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, groups=32, reduction=16, pool=None, is_shortcut=False):\n",
    "        super().__init__()\n",
    "        mid_channels = out_channels // 2\n",
    "        self.conv1 = ConvBR1d(in_channels, mid_channels, 1, 0, 1, )\n",
    "        self.conv2 = ConvBR1d(mid_channels, mid_channels, 3, 1, 1, groups=groups)\n",
    "        self.conv3 = ConvBR1d(mid_channels, out_channels, 1, 0, 1, is_activation=False)\n",
    "        self.se = SEModule(out_channels, reduction)\n",
    "        self.stride = stride\n",
    "        self.is_shortcut = is_shortcut\n",
    "        \n",
    "        if is_shortcut:\n",
    "            self.shortcut = ConvBR1d(in_channels, out_channels, 1, 0, 1, is_activation=False)\n",
    "        if stride > 1:\n",
    "            if pool == 'max':\n",
    "                self.pool = nn.MaxPool1d(stride, stride, ceil_mode=True)\n",
    "            elif pool == 'avg':\n",
    "                self.pool = nn.AvgPool1d(stride, stride, ceil_mode=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        s = self.conv1(x)\n",
    "        s = self.conv2(s)\n",
    "        if self.stride > 1:\n",
    "            s = self.pool(s)\n",
    "        s = self.conv3(s)\n",
    "        s = self.se(s)\n",
    "        \n",
    "        if self.is_shortcut:\n",
    "            if self.stride > 1:\n",
    "                x = F.avg_pool1d(x, self.stride, self.stride, ceil_mode=True) # avg\n",
    "            x = self.shortcut(x)\n",
    "        \n",
    "        x = x + s\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_features=1, in_planes=128, scaling='mul', depth=4, block_depth=2, stride=2):\n",
    "        super().__init__()\n",
    "        if scaling == 'mul':\n",
    "            encoder_channels = in_planes * 2**np.arange(depth+1)\n",
    "        elif scaling == 'add':\n",
    "            encoder_channels = in_planes * np.arange(1, depth+2)\n",
    "        elif scaling == 'const':\n",
    "            encoder_channels = [in_planes] * (depth+1)\n",
    "        \n",
    "        self.encoder_channels = encoder_channels\n",
    "        \n",
    "        self.block0 = nn.Sequential(\n",
    "            ConvBR1d(num_features, encoder_channels[0], kernel_size=5, stride=1, padding=2),\n",
    "            ConvBR1d(encoder_channels[0], encoder_channels[0], kernel_size=3, stride=1, padding=1),\n",
    "            ConvBR1d(encoder_channels[0], encoder_channels[0], kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.blocks = nn.ModuleList([])\n",
    "        in_channels = in_planes\n",
    "        for k, out_channels in enumerate(encoder_channels[1:]):\n",
    "            pool = 'avg' if k==(depth-1) else 'max'\n",
    "            block = nn.Sequential(\n",
    "                SENextBottleneck(in_channels, out_channels, stride=stride, is_shortcut=True, pool=pool, groups=16,\n",
    "                                 reduction=8),\n",
    "              *[SENextBottleneck(out_channels, out_channels, stride=1, is_shortcut=False, groups=16,\n",
    "                                 reduction=8) for i in range(block_depth-1)]\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "            in_channels = out_channels \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block0(x)\n",
    "        out = [x]\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            out.append(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class SCSEModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.cSE = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(in_channels, in_channels // reduction, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels // reduction, in_channels, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.sSE = nn.Sequential(nn.Conv1d(in_channels, 1, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.cSE(x) + x * self.sSE(x)\n",
    "    \n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels, stride=2, with_attention=False):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.conv1 = ConvBR1d(in_channels + skip_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = ConvBR1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        # att\n",
    "        self.att1 = nn.Identity()\n",
    "        self.att2 = nn.Identity()\n",
    "        if with_attention:\n",
    "            self.att1 = SCSEModule(in_channels + skip_channels)\n",
    "            self.att2 = SCSEModule(out_channels)\n",
    "        \n",
    "    def forward(self, x, skip=None):\n",
    "        x = F.interpolate(x, scale_factor=self.stride, mode='nearest') #mode=\"linear\", align_corners=True)\n",
    "        if skip is not None:\n",
    "            x = x[..., :skip.shape[-1]]\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = self.att1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.att2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoder_channels=[64, 128, 256, 512, 1024], stride=2, with_attention=False):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        in_channels = encoder_channels[-1]\n",
    "        for skip_channels in encoder_channels[:-1][::-1]:\n",
    "            block = DecoderBlock(in_channels, skip_channels, skip_channels, stride, with_attention)\n",
    "            self.blocks.append(block)\n",
    "            in_channels = skip_channels\n",
    "\n",
    "    def forward(self, xs):\n",
    "        \n",
    "        x = xs[-1]\n",
    "        for y, block in zip(xs[:-1][::-1], self.blocks):\n",
    "            x = block(x, y)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_features=4, num_classes=12, \n",
    "        in_planes=64, scaling='mul', depth=4, block_depth=2,\n",
    "        stride=2,\n",
    "        with_attention=False,\n",
    "        dropout=0.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert scaling in ['mul', 'add', 'const']\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        # Instantiate the encoder\n",
    "        self.encoder = Encoder(\n",
    "            num_features=num_features, in_planes=in_planes, scaling=scaling,\n",
    "            depth=depth, block_depth=block_depth, stride=stride,\n",
    "        )\n",
    "        encoder_channels = self.encoder.encoder_channels\n",
    "        # Instantiate the decoder\n",
    "        self.decoder = Decoder(encoder_channels, stride, with_attention)\n",
    "        # Include a dropout \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        # Final segmentation layer\n",
    "        self.segmentation_head = nn.Conv1d(encoder_channels[0], num_classes, kernel_size=1, padding=0, stride=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features using the encoder\n",
    "        features = self.encoder(x)\n",
    "        # Apply the decoder from the extracted features\n",
    "        x = self.decoder(features)\n",
    "        # Apply a dropout on the decoder activation map\n",
    "        x = self.dropout(x)\n",
    "        # Apply the segmentation classifier\n",
    "        x = self.segmentation_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c7803",
   "metadata": {},
   "source": [
    "## The Pytorch Lightning Model (calls the Unet [1D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 dropout=0,\n",
    "                 stride=5,\n",
    "                 num_features=4, \n",
    "                 num_classes=12, \n",
    "                 in_planes=64, \n",
    "                 scaling='mul',\n",
    "                 depth=4, \n",
    "                 block_depth=2, \n",
    "                 with_attention=False,\n",
    "                 lr=1e-4,\n",
    "                 scheduler='onecycle',\n",
    "                 max_epochs=10,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        super().__init__()\n",
    "        # save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        # instantiate model\n",
    "        self.net = Unet(\n",
    "                num_features=num_features,\n",
    "                num_classes=num_classes, \n",
    "                in_planes=in_planes, \n",
    "                scaling=scaling, \n",
    "                depth=depth, \n",
    "                block_depth=block_depth,\n",
    "                stride=stride,\n",
    "                with_attention=with_attention,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "        # instantiate the loss function (criterion)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        # instantiate a metric checking method\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def common_step(self, batch):\n",
    "        x = batch['x']\n",
    "        label = batch['label']\n",
    "        \n",
    "        y = self(x)  # forward pass\n",
    "        \n",
    "        loss = self.criterion(y, label)  # loss \n",
    "        accuracy = self.accuracy(y, label)  # metric \n",
    "        return loss, accuracy\n",
    "        \n",
    "    def training_step(self, batch, batch_nb=0, dataloader_idx=0):\n",
    "        # step through once to get loss and accuracy (training)\n",
    "        loss, accuracy = self.common_step(batch)\n",
    "        \n",
    "        self.log('lr', self.optimizers().param_groups[0]['lr'], prog_bar=True)\n",
    "        self.log('loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        self.log('acc', accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb=0):\n",
    "        # step through once to get loss and accuracy (evaluation)\n",
    "        loss, accuracy = self.common_step(batch)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "    def predict_step(self, batch, batch_nb=0):\n",
    "        x = batch['x']\n",
    "        file_num = batch['num'][0]\n",
    "        \n",
    "        y = self(x).softmax(dim=1).argmax(dim=1)\n",
    "        return {\n",
    "            'file_no': file_num.cpu().numpy(),\n",
    "            'Target': y.flatten().cpu().numpy()\n",
    "        }\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # The optimizer\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=0.1)\n",
    "        \n",
    "        # The scheduler\n",
    "        sch_name = self.hparams.scheduler\n",
    "        if sch_name == 'onecycle':\n",
    "            scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer, \n",
    "                max_lr=self.hparams.lr, \n",
    "                pct_start=0.1,\n",
    "                total_steps=self.trainer.estimated_stepping_batches,\n",
    "            )\n",
    "            lr_scheduler = {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'step'\n",
    "            }\n",
    "        elif sch_name == 'plateau':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='max',\n",
    "                min_lr=1e-7,\n",
    "                patience=self.hparams.patience//2,\n",
    "                factor=0.5,\n",
    "            )\n",
    "            lr_scheduler = {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch',\n",
    "                'monitor': 'val_acc'\n",
    "            }\n",
    "        elif sch_name == 'cyclic':\n",
    "            epoch_steps = self.trainer.estimated_stepping_batches // self.hparams.max_epochs\n",
    "            scheduler = optim.lr_scheduler.CyclicLR(\n",
    "                optimizer, \n",
    "                base_lr=1e-7, \n",
    "                max_lr=self.hparams.lr,\n",
    "                mode='triangular2',\n",
    "                step_size_up=epoch_steps,\n",
    "                step_size_down=(self.hparams.max_epochs-1)*epoch_steps,\n",
    "                cycle_momentum=False,\n",
    "            )\n",
    "            lr_scheduler = {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'step',\n",
    "            }\n",
    "            \n",
    "        return {'optimizer': optimizer, 'lr_scheduler': lr_scheduler, \"monitor\": 'val_acc'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1456666",
   "metadata": {},
   "source": [
    "## Extracting the train and test data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af104ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trailing_number(s):\n",
    "    m = re.search(r'\\d+$', s)\n",
    "    return int(m.group()) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for filepath in tqdm(glob.glob('Train_data/*.csv')):\n",
    "    file_id = filepath.split(os.sep)[-1].split('.')[0].lower()\n",
    "    file_no = get_trailing_number(file_id)\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['file_id'] = file_id\n",
    "    df['file_no'] = file_no\n",
    "    train.append(df)\n",
    "\n",
    "train = pd.concat(train, axis=0, ignore_index=True).sort_values(['file_no', 'time'])\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for filepath in tqdm(glob.glob('Test_data/*.csv')):\n",
    "    file_id = filepath.split(os.sep)[-1].split('.')[0].lower()\n",
    "    file_no = get_trailing_number(file_id)\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['file_id'] = file_id\n",
    "    df['file_no'] = file_no\n",
    "    df['ID'] = df['time'].apply(lambda t: f\"{file_id}_{t}\")\n",
    "    test.append(df)\n",
    "\n",
    "test = pd.concat(test, axis=0, ignore_index=True).sort_values(['file_no', 'time'])\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.file_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.file_no==34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f039cb",
   "metadata": {},
   "source": [
    "## The Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068211f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkDataset(Dataset):\n",
    "    def __init__(self, df, repeats=1):\n",
    "        self.repeats = repeats\n",
    "        cols = ['time','portPktIn', 'portPktOut', 'qSize']\n",
    "        self.data = [np.log1p(df[df.file_no == file_no][cols].T.values /1e6) for file_no in df.file_no.unique()]\n",
    "        \n",
    "        self.file_nums = df.file_no.unique()\n",
    "        if 'label' in df.columns:\n",
    "            self.labels = [df[df.file_no == file_no]['label'].values for file_no in df.file_no.unique()]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data) * self.repeats\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self.data)\n",
    "        \n",
    "        sample = dict(\n",
    "            x=self.data[idx].astype('float32'),\n",
    "            num=self.file_nums[idx],\n",
    "        )\n",
    "        if hasattr(self, 'labels'):\n",
    "            sample['label'] = self.labels[idx]\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a42e0",
   "metadata": {},
   "source": [
    "## Training Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import inspect\n",
    "import shutil\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.progress.tqdm_progress import TQDMProgressBar\n",
    "\n",
    "\n",
    "# free temporarily used memory\n",
    "def remove_dir(path):\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# free CPU and GPU memory as needed and required for cross-validation\n",
    "def free_memory(to_delete: list):\n",
    "    calling_namespace = inspect.currentframe().f_back\n",
    "\n",
    "    for _var in to_delete:\n",
    "        calling_namespace.f_locals.pop(_var, None)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# get meaningful callbacks\n",
    "def get_callbacks(args, fold=None):\n",
    "    start_name = \"\"\n",
    "    if fold is not None:\n",
    "        start_name = f\"fold{fold}-\"\n",
    "    \n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "          filename=start_name + \"{epoch}-{val_loss:0.4f}-{val_acc:0.4f}\",\n",
    "          monitor='val_acc',\n",
    "          mode='max',\n",
    "          verbose=False,\n",
    "          save_last=False,\n",
    "          save_top_k=1,\n",
    "          save_weights_only=True\n",
    "    )\n",
    "    \n",
    "    early_stop_callback = pl.callbacks.EarlyStopping(\n",
    "        monitor=\"val_acc\",\n",
    "        mode='max',\n",
    "        patience=args.patience,\n",
    "        verbose=True,\n",
    "        strict=True,\n",
    "        check_finite=True,\n",
    "        check_on_train_epoch_end=False\n",
    "    )\n",
    "    prog_rate = TQDMProgressBar(refresh_rate=1)\n",
    "    \n",
    "    return [\n",
    "        checkpoint_callback,\n",
    "        early_stop_callback,\n",
    "        prog_rate,\n",
    "    ]\n",
    "\n",
    "\n",
    "# get the dataloaders per fold\n",
    "def get_loaders(train_index, val_index):\n",
    "    train_df = train[~train.file_no.isin(val_index)]\n",
    "    val_df = train[train.file_no.isin(val_index)]\n",
    "    \n",
    "    dst_train = NetworkDataset(train_df, args.repeats)\n",
    "    dst_val = NetworkDataset(val_df)\n",
    "\n",
    "    train_loader = DataLoader(dst_train, batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(dst_val, batch_size=1, shuffle=False)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3fc40",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d7585e",
   "metadata": {},
   "source": [
    "## Creating a simple prediction model that works with the trained models without all the nuts and bolts needed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(pl.LightningModule):\n",
    "    def __init__(self, ckpt_paths, mode='mean'):\n",
    "        super().__init__()\n",
    "        if isinstance(ckpt_paths, str):\n",
    "            ckpt_paths = [ckpt_paths]\n",
    "        self.mode = mode\n",
    "        self.models = nn.ModuleList([\n",
    "            Model.load_from_checkpoint(ckpt_path, map_location='cpu') for ckpt_path in ckpt_paths\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.stack([model(x).softmax(dim=1) for model in self.models], dim=0)\n",
    "        if self.mode == 'mean':\n",
    "            out = out.mean(dim=0)\n",
    "        elif self.mode == 'max':\n",
    "            out = out.max(dim=0)\n",
    "        return out\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx=0):\n",
    "        x = batch['x']\n",
    "        file_num = batch['num'][0]\n",
    "        \n",
    "        y = self(x)\n",
    "        if self.mode in ['max', 'mean']:\n",
    "            y = y.argmax(dim=1).flatten().cpu().numpy()\n",
    "        else:\n",
    "            y = y.cpu().numpy()\n",
    "        \n",
    "        return {\n",
    "            'file_no': file_num.cpu().numpy(), \n",
    "            'Target': y, #.flatten().cpu().numpy()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e2f98",
   "metadata": {},
   "source": [
    "loading the sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a1a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('SampleSubmission.csv')\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a77491",
   "metadata": {},
   "source": [
    "## Instantiate the testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_test = NetworkDataset(test)\n",
    "\n",
    "test_loader = DataLoader(dst_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898b5f5",
   "metadata": {},
   "source": [
    "## Get the trained checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths1 = glob.glob('logs/se-c128*/se-c96-s5-l7*/checkpoints/*')\n",
    "checkpoint_paths1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths2 = glob.glob('logs/se-c128*/se-c128-s5-l7*/checkpoints/*')\n",
    "checkpoint_paths2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths3 = glob.glob('logs/se-c128*/se-c128-s5-l5*/checkpoints/*')\n",
    "checkpoint_paths3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc8591",
   "metadata": {},
   "source": [
    "## Get predictions with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e558dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths = checkpoint_paths1 + checkpoint_paths2 + checkpoint_paths3\n",
    "pred_model = EnsembleModel(checkpoint_paths, mode='mean')\n",
    "preds = trainer.predict(pred_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65cbd27",
   "metadata": {},
   "source": [
    "Convert the prediction into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98198945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(preds)\n",
    "df_preds['time'] = df_preds['Target'].apply(lambda t: np.arange(len(t)))\n",
    "df_preds = df_preds.explode(['Target', 'time'])\n",
    "df_preds['ID'] = df_preds.apply(lambda row: f\"test{row['file_no']}_{row['time']}\", axis=1)\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a2af7",
   "metadata": {},
   "source": [
    "Remove unwanted columns and ensure compactibility with sample submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75046e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = df_preds[['ID', 'Target']].reset_index(drop=True)\n",
    "sub = sub.set_index('ID').loc[sample_sub['ID']].reset_index()\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ecf83",
   "metadata": {},
   "source": [
    "## Get Ready for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d7e9d8",
   "metadata": {},
   "source": [
    "Consider a post-processing based on the data (information provided in the challenge overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63633f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_procs(df0):\n",
    "    df = df0.copy()\n",
    "    df['file'] = df['ID'].apply(lambda x: x.split('_')[0])\n",
    "    df['before'] = df.groupby('file')['Target'].shift(-1)\n",
    "    df['after'] = df.groupby('file')['Target'].shift(1)\n",
    "    \n",
    "    mask = (df.Target != df.before) & (df.Target != df.after) & (df.after == df.before)\n",
    "    df.loc[mask, 'Target'] = df[mask]['before']\n",
    "    return df[['ID', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bacbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"ensembles\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = post_procs(sub)\n",
    "sub.to_csv(f'ensembles/final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa56be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4ex",
   "language": "python",
   "name": "ai4ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
